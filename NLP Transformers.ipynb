{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32cb9d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "clf= pipeline('sentiment-analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6b6c175",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.9905688166618347}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf(\"I don't like fruits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16d1a5b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to facebook/bart-large-mnli and revision c626438 (https://huggingface.co/facebook/bart-large-mnli).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    }
   ],
   "source": [
    "classifier=pipeline('zero-shot-classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30298b1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': 'Narendra Modi is an emerging leader in the Indian Government',\n",
       " 'labels': ['Politics', 'Sports', 'Entertainment'],\n",
       " 'scores': [0.9713423848152161, 0.014636620879173279, 0.014020981267094612]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\n",
    "\"Narendra Modi is an emerging leader in the Indian Government\",\n",
    "    candidate_labels= [\"Politics\", \"Sports\", \"Entertainment\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2ff43a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': 'MS Dhoni is the greatest leader and captain ever to play in the Indian cricket team',\n",
       " 'labels': ['Sports', 'Entertainment', 'Politics'],\n",
       " 'scores': [0.9734850525856018, 0.02092134952545166, 0.005593602079898119]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\n",
    "\"MS Dhoni is the greatest leader and captain ever to play in the Indian cricket team\",\n",
    "    candidate_labels= [\"Politics\", \"Sports\", \"Entertainment\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6dfa06e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': 'Sharukh Khan created an empire of his own in the Bollywood industry',\n",
       " 'labels': ['Entertainment', 'Sports', 'Politics'],\n",
       " 'scores': [0.9875079989433289, 0.007083845790475607, 0.005408161785453558]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\n",
    "\"Sharukh Khan created an empire of his own in the Bollywood industry\",\n",
    "    candidate_labels= [\"Politics\", \"Sports\", \"Entertainment\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aaa2bf5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to gpt2 and revision 6c0e608 (https://huggingface.co/gpt2).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    }
   ],
   "source": [
    "text= pipeline('text-generation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cef7affd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'The significance of Transformers model over LSTM model is that I can see a huge difference. The fact these models are built using superpowers from an alternative perspective from the point of view of the player still, the player is a little much, still'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text(\"The significance of Transformers model over LSTM model is\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7813e4eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"Deep Learning is a language development framework.\\n\\nThere are over 30 languages, and every language has its own requirements. So here are some basics on programming language requirements – how to know what you're doing, learn how to implement a functional language into\"}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text(\"Deep Learning is\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35ad2e34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'In this course we will teach you how to build on our existing skills. This course is focused on building a functional foundation on JavaScript in general.\\n\\n\\nIf you are not comfortable with using JavaScript in your app (such as a web app),'},\n",
       " {'generated_text': 'In this course we will teach you how to build a powerful and powerful mobile app like the Graphene iPhone.\\n\\n\\n\\n\\nThe Graphene iPhone\\nThe Graphene iPhone is a super simple phone with a big 3D glass'},\n",
       " {'generated_text': \"In this course we will teach you how to build the ability of the language, how to use the language and the language's function and create a way to use it in JavaScript. In this section you will learn how to build the language to use it\"}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prt_model= pipeline('text-generation', model=\"distilgpt2\")\n",
    "\n",
    "prt_model(\"In this course we will teach you how to build\", num_return_sequences= 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ea87de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilroberta-base and revision ec58a5b (https://huggingface.co/distilroberta-base).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Some weights of the model checkpoint at distilroberta-base were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "mask= pipeline(\"fill-mask\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94642e5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.02123112417757511,\n",
       "  'token': 26956,\n",
       "  'token_str': ' linear',\n",
       "  'sequence': 'The best model for NLP is linear model'},\n",
       " {'score': 0.01439797692000866,\n",
       "  'token': 9284,\n",
       "  'token_str': ' hybrid',\n",
       "  'sequence': 'The best model for NLP is hybrid model'},\n",
       " {'score': 0.010330939665436745,\n",
       "  'token': 25897,\n",
       "  'token_str': ' modular',\n",
       "  'sequence': 'The best model for NLP is modular model'}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask(\"The best model for NLP is <mask> model\", top_k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c443c045",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision f2482bf (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'entity': 'I-PER',\n",
       "  'score': 0.9989404,\n",
       "  'index': 4,\n",
       "  'word': 'Rick',\n",
       "  'start': 8,\n",
       "  'end': 12},\n",
       " {'entity': 'I-LOC',\n",
       "  'score': 0.99771464,\n",
       "  'index': 9,\n",
       "  'word': 'Manchester',\n",
       "  'start': 27,\n",
       "  'end': 37},\n",
       " {'entity': 'I-LOC',\n",
       "  'score': 0.999426,\n",
       "  'index': 11,\n",
       "  'word': 'USA',\n",
       "  'start': 41,\n",
       "  'end': 44}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner= pipeline(\"ner\")\n",
    "ner(\"Hi I am Rick and I live in Manchester in USA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b560716a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score': 0.33240848779678345,\n",
       " 'start': 107,\n",
       " 'end': 154,\n",
       " 'answer': 'consciousness is closely related to the reality'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_n_a= pipeline(\"question-answering\")\n",
    "\n",
    "q_n_a(\n",
    "    question= \"Is consciousness a part of the reality or the reality is the result of consciousness?\",\n",
    "    context= \"The reality we often perceive as we observe may be a result of the intrinsic complex subconscious mind but consciousness is closely related to the reality\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "942b27a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score': 0.27682632207870483, 'start': 15, 'end': 26, 'answer': 'good actors'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_n_a= pipeline(\"question-answering\")\n",
    "\n",
    "q_n_a(\n",
    "    question= \"Who is the king of Indian Cinema ?\",\n",
    "    context= \"There are many good actors in the indian cinema industry but among them the best one needs to be figured out\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "323e4ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    }
   ],
   "source": [
    "summ= pipeline(\"summarization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "01b3e5c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': ' YOLOs have emerged as the predominant paradigm in the field of real-time object detection owing to their effective balance between computational cost and detection performance . The reliance on the non-maximum suppression (NMS) for post-processing hampers the end-to-end deployment of YOLOOs and adversely impacts the inference latency .'}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summ(\n",
    "\"\"\"\n",
    "Over the past years, YOLOs have emerged as the predominant paradigm in the field of real-time object detection owing to their effective balance between computational cost and detection performance. Researchers have explored the architectural designs, optimization objectives, data augmentation strategies, and others for YOLOs, achieving notable progress. However, the reliance on the non-maximum suppression (NMS) for post-processing hampers the end-to-end deployment of YOLOs and adversely impacts the inference latency. Besides, the design of various components in YOLOs lacks the comprehensive and thorough inspection, resulting in noticeable computational redundancy and limiting the model’s capability. It renders the suboptimal efficiency, along with considerable potential for performance improvements. In this work, we aim to further advance the performance-efficiency boundary of YOLOs from both the post-processing and the model architecture. To this end, we first present the consistent dual assignments for NMS-free training of YOLOs, which brings the competitive performance and low inference latency simultaneously. Moreover, we introduce the holistic efficiency-accuracy driven model design strategy for YOLOs. We comprehensively optimize various components of YOLOs from both the efficiency and accuracy perspectives, which greatly reduces the computational overhead and enhances the capability. The outcome of our effort is a new generation of YOLO series for real-time end-to-end object detection, dubbed YOLOv10. Extensive experiments show that YOLOv10 achieves the state-of-the-art performance and efficiency across various model scales. For example, our YOLOv10-S is 1.8\n",
    "× faster than RT-DETR-R18 under the similar AP on COCO, meanwhile enjoying 2.8\n",
    "× smaller number of parameters and FLOPs. Compared with YOLOv9-C, YOLOv10-B has 46% less latency and 25% fewer parameters for the same performance\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b0ffd756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers[sentencepiece] in c:\\users\\dibyojit\\appdata\\local\\rstudio\\ctx\\lib\\site-packages (4.32.1)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\dibyojit\\appdata\\local\\rstudio\\ctx\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\dibyojit\\appdata\\local\\rstudio\\ctx\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: filelock in c:\\users\\dibyojit\\appdata\\local\\rstudio\\ctx\\lib\\site-packages (from transformers[sentencepiece]) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in c:\\users\\dibyojit\\appdata\\local\\rstudio\\ctx\\lib\\site-packages (from transformers[sentencepiece]) (0.15.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\dibyojit\\appdata\\roaming\\python\\python39\\site-packages (from transformers[sentencepiece]) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\dibyojit\\appdata\\local\\rstudio\\ctx\\lib\\site-packages (from transformers[sentencepiece]) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\dibyojit\\appdata\\local\\rstudio\\ctx\\lib\\site-packages (from transformers[sentencepiece]) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\dibyojit\\appdata\\local\\rstudio\\ctx\\lib\\site-packages (from transformers[sentencepiece]) (2022.7.9)\n",
      "Requirement already satisfied: requests in c:\\users\\dibyojit\\appdata\\local\\rstudio\\ctx\\lib\\site-packages (from transformers[sentencepiece]) (2.31.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\dibyojit\\appdata\\local\\rstudio\\ctx\\lib\\site-packages (from transformers[sentencepiece]) (0.13.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\dibyojit\\appdata\\local\\rstudio\\ctx\\lib\\site-packages (from transformers[sentencepiece]) (0.3.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\dibyojit\\appdata\\local\\rstudio\\ctx\\lib\\site-packages (from transformers[sentencepiece]) (4.65.0)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in c:\\users\\dibyojit\\appdata\\local\\rstudio\\ctx\\lib\\site-packages (from transformers[sentencepiece]) (0.2.0)\n",
      "Requirement already satisfied: protobuf in c:\\users\\dibyojit\\appdata\\local\\rstudio\\ctx\\lib\\site-packages (from transformers[sentencepiece]) (4.24.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\dibyojit\\appdata\\local\\rstudio\\ctx\\lib\\site-packages (from huggingface-hub<1.0,>=0.15.1->transformers[sentencepiece]) (2023.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\dibyojit\\appdata\\local\\rstudio\\ctx\\lib\\site-packages (from huggingface-hub<1.0,>=0.15.1->transformers[sentencepiece]) (4.10.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\dibyojit\\appdata\\local\\rstudio\\ctx\\lib\\site-packages (from tqdm>=4.27->transformers[sentencepiece]) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dibyojit\\appdata\\local\\rstudio\\ctx\\lib\\site-packages (from requests->transformers[sentencepiece]) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dibyojit\\appdata\\local\\rstudio\\ctx\\lib\\site-packages (from requests->transformers[sentencepiece]) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dibyojit\\appdata\\local\\rstudio\\ctx\\lib\\site-packages (from requests->transformers[sentencepiece]) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dibyojit\\appdata\\local\\rstudio\\ctx\\lib\\site-packages (from requests->transformers[sentencepiece]) (2023.7.22)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers[sentencepiece]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "371c4320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "593469ffc6f8444bb60f7f0cf0dbeabe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading source.spm:   0%|          | 0.00/509k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DIBYOJIT\\AppData\\Local\\RStudio\\ctx\\lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\DIBYOJIT\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41c4f4abe1144629b7198d48b1115aa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading target.spm:   0%|          | 0.00/1.02M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8459d5df52f74ed1af48b1f4ac0b2703",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.json:   0%|          | 0.00/1.64M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DIBYOJIT\\AppData\\Local\\RStudio\\ctx\\lib\\site-packages\\transformers\\models\\marian\\tokenization_marian.py:194: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    }
   ],
   "source": [
    "translate= pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-en-jap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "85e8c5d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'translation_text': 'これ が 四方 の 境 で あ っ て , 顔 と 顔 を 放 つ 者 と な る .'}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(\"This course is all about hugging face and transformers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "73c4a7d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'translation_text': 'あなた がた は どう なさ っ た の か .'}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(\"Hello how are you\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
